{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/cs124/labs/blob/main/Lab2_NaiveBayes_Solutions.md\n",
    "lab 2 part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training set\n",
    "negative_set = [\"the dangerous bears\", \"bears destroyed the yard\"] \n",
    "positive_set = [\"the beautiful redwood trees\"]\n",
    "test_set = ['the friendly bears rest']\n",
    "train_set = []\n",
    "train_set.extend(negative_set)\n",
    "train_set.extend(positive_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|V| = 8 n+ = 4 n- = 7\n"
     ]
    }
   ],
   "source": [
    "def wordSetFromText(sentence: str):\n",
    "    return set(sentence.split(' '))\n",
    "\n",
    "def setFromTextList(sentences: []):\n",
    "    a_set = set()\n",
    "    for sentence in sentences:\n",
    "        a_set.update(wordSetFromText(sentence))\n",
    "        pass\n",
    "    return a_set\n",
    "\n",
    "def listFromTextList(sentences: []):\n",
    "    a_list = []\n",
    "    for sentence in sentences:\n",
    "        a_list.extend(sentence.split(' '))\n",
    "        pass\n",
    "    return a_list\n",
    "\n",
    "V = setFromTextList(train_set)\n",
    "\n",
    "\n",
    "\n",
    "n_positive = listFromTextList(positive_set)\n",
    "n_negative = listFromTextList(negative_set)\n",
    "\n",
    "print(f'|V| = {len(V)} n+ = {len(n_positive)} n- = {len(n_negative)}')\n",
    "n = [n_positive, n_negative]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(+) = 0.3333333333333333 P(-) = 0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "P_positive = len(positive_set) / len(train_set)\n",
    "P_negative = len(negative_set) / len(train_set)\n",
    "\n",
    "print(f'P(+) = {P_positive} P(-) = {P_negative}')\n",
    "P = [P_positive, P_negative]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|V| = 8, n- = 7, n+ = 4 \n",
    "\n",
    "P(-) = 2/3, P(+) = 1/3\n",
    "\n",
    "P(the | - ) = (1 + 2) / (n- + |V|) = (1 + 2) / (7 + 8) = 3/15 = 1/5\n",
    "\n",
    "P(the | + ) = (1 + 1) / (n+ + |V|) = (1 + 1) / (4 + 8) = 2/12 = 1/6\n",
    "\n",
    "P(friendly | - ) = unseen in training*\n",
    "\n",
    "P(friendly | + ) = unseen in training*\n",
    "\n",
    "P(bears | - ) = (1 + 2) / (n- + |V|) = (1 + 2) / (7 + 8) = 3/15 = 1/5\n",
    "\n",
    "P(bears | + ) = (1 + 0) / (n+ + |V|) = (1 + 0) / (4 + 8) = 1/12\n",
    "\n",
    "P(rest | - ) = unseen in training*\n",
    "\n",
    "P(rest | + ) = unseen in training*\n",
    "\n",
    "* Words in test set that were completely unseen in training are simply removed from the test set. So, we do not compute these probabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C = {+, -}\n",
    "\n",
    "P(c | \"the friendly bears rest\") ∝ P(c) * P (\"the friendly bears rest\" | c)\n",
    "\n",
    "= P(c) * P(the | c) * P(friendly | c) * P(bears | c) * P(rest | c) ~= P(c) * P(the | c) * P(bears | c), 'friendly' and 'rest' are unseen in training, so we ignore it in computing probabilities\n",
    "\n",
    "P( - | \"the friendly bears rest\") ∝ (2/3) * (1/5) * (1/5) = 0.02667\n",
    "\n",
    "P( + | \"the friendly bears rest\") ∝ (1/3) * (1/6) * (1/12) = 0.00463\n",
    "\n",
    "P( - | \"the friendly bears rest\") is greater, so the test set sentence is classified as class negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{('the friendly bears rest', 0): 0.013888888888888888, ('the friendly bears rest', 1): 0.04000000000000001}\n",
      "Sentiment of \"the friendly bears rest\" is negative\n",
      "{('go bears', 0): 0.08333333333333333, ('go bears', 1): 0.2}\n",
      "Sentiment of \"go bears\" is negative\n",
      "{('go trees', 0): 0.16666666666666666, ('go trees', 1): 0.06666666666666667}\n",
      "Sentiment of \"go trees\" is positive\n"
     ]
    }
   ],
   "source": [
    "test_set.extend(['go bears', 'go trees'])\n",
    "\n",
    "for sentence in test_set:\n",
    "    result = {}\n",
    "    for word in sentence.split(' '):\n",
    "        if word in V:\n",
    "            for i in range(len(n)):\n",
    "                n_sentiment = n[i]\n",
    "                P_sentiment = P[i]\n",
    "                probality = (n_sentiment.count(word) + 1) / (len(n_sentiment) + len(V))\n",
    "                result[(word, i)] = probality \n",
    "                pass\n",
    "            pass\n",
    "        pass\n",
    "    #print(result)\n",
    "    final_probality = {}   \n",
    "    for i in range(len(n)):\n",
    "        product = 1.0\n",
    "        for word in sentence.split(' '):\n",
    "            if word in V:\n",
    "                product *= result[(word, i)]\n",
    "                pass\n",
    "            pass\n",
    "        final_probality[(sentence, i)] = product\n",
    "        pass\n",
    "    print(final_probality)   \n",
    "    print(f'Sentiment of \"{sentence}\" is {\"positive\" if max(final_probality, key=final_probality.get)[1] == 0 else \"negative\"}')  \n",
    "      \n",
    "    pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
